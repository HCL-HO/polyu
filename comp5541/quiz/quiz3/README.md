# COMP5541 Quiz 3

### 1. Because it is not possible to construct a graph on 2D images, the graph convolutional neural layers cannot be applied for image classification task. (5 points)

A. Yes

B. No

### 2. It is unable to compute the degree matrix from the adjacency matrix. (5 points)

A. Yes

B. No

### 3. Given a graph with 1000 nodes connected, 600 nodes have class labels for training. We train a graph convolutional neural network for node classification. Because the remaining 400 nodes do not have labels, their node features will never be used during training. (5 points)

A. Yes

B. No

### 4. The DiffPool method cannot increase the total number of (virtual) nodes in the graph. (5 points)

A. Yes

B. No

### 5. Autoencoder can only process graph data points. (5 points)

A. Yes

B. No

### 6. The capsule neural layer is equivalent to a fully-connected layer if each capsule has only one neuron. (5 points)

A. Yes

B. No

### 7. Transposed convolutional layer is not a linear transformation. (5 points)

A. Yes

B. No

### 8. Unsupervised learning does not need any signal to supervise the network. (5 points)

A. Yes

B. No

### 9. Autoencoder cannot be used for dimension reduction. (5 points)

A. Yes

B. No

### 10. The learned latent representations by an autoencoder can be further classified using kmeans clustering method (5 points)

A. Yes

B. No

### 11. In a variational autoencoder, each input data point is mapped to a distribution. (5 points)

A. Yes

B. No

### 12. In a variational autoencoder, we directly sample a latent code from the learned mean and sigma, and then feed it into the decoder to compute the likelihood loss for training. (5 points)

A. Yes

B. No

### 13. The KL divergence only measures the difference between the means of two distributions. (5 points)

A. Yes

B. No

### 14. In a variational autoencoder, when we only minimize the KL loss, the parameters of the decoder will be automatically optimised. (5 points)

A. Yes

B. No

### 15. The reparameterization trick of variational autoencoder is used to better compute the KL loss. (5 points)

A. Yes

B. No

### 16. The reparameterization trick is to sample a data point from a standard normal distribution, i.e., u(0,1). It is impossible to alternatively sample the data point from a non-standard normal distribution, e.g., u(1, 2). (5 points)

A. Yes

B. No

### 17. In a Generative Adversarial Network, the discriminator can be seen as a binary classifier. (5 points)

A. Yes

B. No

### 18. In a Generative Adversarial Network, if we regard the fake images as the category "1", the real images as the category "O", the entire network can be optimized using the original GAN loss functions. (5 points)

A. Yes

B. No

### 19. Given 10 classes of hand-written digits (MNIST dataset) as the training data, the generator can always generate all 10 classes of fake digits after enough epochs. (5 points)

A. Yes

B. No

### 20. Variational autoencoder can always reconstruct much sharper images than generative adversarial networks. (5 points)

A. Yes

B. No



## Solution
1. No
2. No
3. No
4. No
5. No
6. No
7. No
8. No
9. No
10. Yes
11. Yes
12. No
13. No
14. No
15. No
16. No
17. Yes
18. No
19. No
20. No